{
  "hash": "841b071a28f039724b3af899e1f214ae",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: T is for Topology\nauthor:\n  - name: Tanya Strydom\n    orcid: 0000-0001-6067-1349\n    corresponding: true\n    email: t.strydom@sheffield.ac.uk\n    roles:\n      - Investigation\n      - Project administration\n      - Software\n      - Visualisation\n    affiliations:\n      - University of Sheffield\n  - name: Andrew P. Beckerman\n    orcid: 0000-0002-7859-8394\n    corresponding: false\n    roles: []\n    affiliations:\n      - University of Sheffield\nkeywords:\n  - food web\n  - network construction\nabstract: |\n  Pending...\nplain-language-summary: |\n  We want to know a bit more about the different network topology generators (predict tools) and how they differ - *i.e.,*  their strengths and weaknesses\nkey-points:\n  - Important point 1\n  - Important point 2\ndate: last-modified\nbibliography: references.bib\ncitation:\n  container-title: Earth and Space Science\nnumber-sections: true\n---\n\n:::{#f3580377 .cell .markdown}\n## Introduction\n\nThe standard run of the mill that we cannot always feasibly construct networks because 1. hard, 2. time (yay dinosaurs, but also the future and impending doom I guess), and 3. probably something else meaningful that's just slipping my mind at the moment.\n\nMaybe a brief history of the development of predictive tools? Sort of where the theory/body of work was based and how that has changed?\n\nMaybe start here with discussing the core mechanistic differences that models will work at --- some are really concerned about (and thus constrained by) structure, others are more mechanistic in nature *i.e.,* species *a* has the capacity to eat species *b* because traits (read gob size), and then you get @rohrModelingFoodWebs2010 and @strydomFoodWebReconstruction2022 that sit in the weird liminal latent space...\n\nAt some point we are going to need to discuss the key differences and implications between predicting a metaweb and a network realisation.\n\n> Do we need to delve into individual-based networks? (*sensu* Tinker 2012, Ara√∫jo 2008) I think its probably a step too far and one starts delving into apples and pears type of comparisons. Especially since these work off of already existing networks and its more about about 'tweaking' those - so not so much *de novo* predictions. Although this might be useful to keep in mind when it comes to re-wiring... Also on that note do we opn the re-wiring door here in this ms or wait it out a bit.\n\n## Data & Methods {#sec-data-methods}\n\n### Overview of topology generators\n\nI know table are awful but in this case they may make more sense\n\n| Model             | Reference                                    | Core Mechanism     |\n|-------------------|----------------------------------------------|--------------------|\n| Niche model       | @cohenStochasticTheoryCommunity1997          | structural         |\n| Cascade model     | @williamsSimpleRulesYield2000                | structural         |\n| PFIM              | @shawFrameworkReconstructingAncient2024      | mechanistic        |\n| Log-ratio         | @rohrModelingFoodWebs2010                    | latent trait space |\n| Nested hierarchy  | @cattinPhylogeneticConstraintsAdaptation2004 |                    |\n| ADBM              | @petcheySizeForagingFood2008                 | mechanistic        |\n| Stochastic        | @rossbergFoodWebsExperts2006                 |                    |\n| Transfer learning | @strydomFoodWebReconstruction2022            | latent trait space |\n| Trait-based       | @caronAddressingEltonianShortfall2022        | mechanistic        |\n\n: Lets make a table that gives an overview of the different topology generators that we will look at {#tbl-history}\n\n### Datasets used\n\nHere I think we need to span a variety of domains, at minimum aquatic and terrestrial but maybe there should be a 'scale' element as well *i.e.,* a regional and local network. I think there is going to be a 'turning point' where structural will take over from mechanistic in terms of performance. More specifically at local scales bioenergetic constraints (and co-occurrence) may play a bigger role in structuring a network whereas at the metaweb level then mechanistic may make more (since by default its about who can potentially interact and obviously not constrained by real-world scenarios) *sensu* @caronTrophicInteractionModels2023\n\n## Results\n\nHow we want to compare and contrast. I think there won't be a 'winner' and thus we need to think of 'tests' that are going to measure performance in different situations/settings. With that in mind I think some valuable points to consider would be:\n\n* Structural vs pairwise link predictions (graph vs node level)\n  * % of links correctly retrieved\n  * connectence\n  * trophic level\n  * generalism vs specialism\n  * something related to false positives/negatives\n* Data 'cost' (some methods might need a lot lot of supporting data vs something very light weight)\n* I think it would be remiss to not also take into consideration computational cost\n* something about the network output - I'm acknowledging my biases and saying that probabilistic (or *maybe* weighted) links are the way\n\n## Conclusion\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n:::\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}