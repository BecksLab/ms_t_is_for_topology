---
title: Quantitative approach to topology generators
authors:
  - name: Tanya Strydom
    id: ts
    orcid: 0000-0001-6067-1349
date: last-modified
bibliography: ../references.bib
---

I think in the long run I will probably turn the other repo ([BecksLab/topology_generators](https://github.com/BecksLab/topology_generators)) into a project that we can then access and I will port all of the working code here... I think it will just come down to what the 'cost' is of the computational side of things and how convoluted it might end up looking.

Anyway so for now I am just pulling in the INTERIM data from some of the models. This uses (for now) 20 mangal [@poisotMangalMakingEcological2016] datasets and just generates some networks for using the niche and cascade models. The 'results' for now is just counting the number of links each model generates for each network because that's what my brain decided on doing...

```{r}
#| include: false
#| warning: false
library(tidyverse)

# download file from other repo
download.file("https://raw.githubusercontent.com/BecksLab/topology_generators/main/data/topology_summary.csv", "../notebooks/data/topology_models.csv")

df = read.csv("data/topology_models.csv")  %>% 
        filter(complexity_real != 0) %>% 
        mutate(ratio_real = top_real/basal_real,
                top_real = NULL,
                basal_real = NULL,
                ratio_mod = top_mod/basal_mod,
                top_mod = NULL,
                basal_mod = NULL) %>%
        pivot_longer(
            cols = c(complexity_real, distance_real, connectance_real, ratio_real), 
            names_to = "real",
            values_to = "real_val")  %>% 
        pivot_longer(
            cols = c(complexity_mod, distance_mod, connectance_mod, ratio_mod), 
            names_to = "test",
            values_to = "model_val")  %>% 
        mutate(
            real = str_extract(real, "[^_]*"),
            test = str_extract(test, "[^_]*"))  %>% 
        filter(real == test)
```

From a data transformation perspective instead of looking at the raw number of 'top' (zero vulnerability) and 'bottom' (zero generality) species we can instead look at the ratio of top:bottom. A small (< 1) number will thus be indicative of a 'bottom-heavy' network and the opposite for larger numbers

Lets tart by summarising the 'raw' data as box plots just to see what it looks like before we calculate the Z scores

```{r}
#| warning: false
#| echo: false
#| label: fig-boxplot
#| fig-cap: "Boxplot looking at raw values for each measurement for each model. The horizontal line represents the true overall mean for each measurement"

ggplot(df) +
    geom_boxplot(aes(x = real,
                    y = model_val,
                    colour = model)) +
    geom_hline(data = df  %>% 
                        group_by(real)  %>% 
                        reframe(mu_sim = mean(model_val, na.rm = TRUE)),
                aes(yintercept = mu_sim),
                alpha = 0.7) +
    facet_wrap(vars(real),
                scales = 'free') +
    scale_size(guide = 'none') +
    coord_cartesian(expand = FALSE) +
    theme_classic() +
    theme(panel.border = element_rect(colour = 'black',
                                      fill = "#ffffff00"))

```


Now we can look at the Z scores for the different models for the different network measures that we use.

Here 'Z score' is calculated as:

$$
 Z = \frac{x_{real}-\mu_{model}}{\sigma_{model}}
$$

```{r}
#| warning: false
#| echo: false
#| label: fig-topology
#| fig-cap: "Z-scores for network summary statistics. Negative Z-scores indicate a (mean) value greater than expected. The magnitude of Z-score probably also tells us how 'variable'/constrained the model is... I am aware that there are no Z scores for some of the Random models and am looking into it"

ggplot(df %>% 
        group_by(id, real, model)  %>% 
        reframe(x_real = real_val,
                mu_sim = mean(model_val, na.rm = TRUE),
                sd_sim = sd(model_val, na.rm = TRUE)) %>%
        mutate(z_score = ((x_real-mu_sim)/sd_sim)) %>%
        distinct()) +
    geom_vline(aes(xintercept = 0)) +
    geom_histogram(aes(x = z_score,
                    fill = model),
                colour = "#ffffff00") +
    facet_grid(rows = vars(model),
                cols = vars(real),
                scales = "free") +
    scale_size(guide = 'none') +
    coord_cartesian(expand = FALSE) +
    theme_classic() +
    theme(panel.border = element_rect(colour = 'black',
                                      fill = "#ffffff00"))

```

## References {.unnumbered}

::: {#refs}
:::