---
title: T is for Topology
author:
  - name: Tanya Strydom
    id: ts
    orcid: 0000-0001-6067-1349
    corresponding: true
    email: t.strydom@sheffield.ac.uk
    roles:
      - Words
      - Nonsense
      - Rascality
      - Visualisation (although absent)
    affiliation:
      - id: sheffield
        name: School of Biosciences, University of Sheffield
  - name: Andrew P. Beckerman
    id: apb
    orcid: 0000-0002-7859-8394
    corresponding: false
    roles: []
    affiliations:
      - ref: sheffield
funding: "The author(s) received no specific funding for this work. Well they did I just haven't done the "
keywords:
  - food web
  - network construction
abstract: |
  There are many reasons one might want to generate a network and there are many tools on the market that might make that possible. However not all tools are created equally and there is reason to assume that not all networks will suit most purposes. Here the aim is to compare and contrast the different topology generating tools that are on the market and see where they shine and where they fall flat. There probably isn't one model to rule them all but it doesn't mean that we shouldn't be critical when we think about the model we want to use.
plain-language-summary: |
  We want to know a bit more about the different network topology generators (prediction tools) and how they differ - *i.e.,*  their strengths and weaknesses
date: last-modified
bibliography: references.bib
citation:
  container-title: Some fancy journal
number-sections: true
jupyter: python3
---

## Introduction

* In order to construct a 'perfect' network *i.e.,* one which *perfectly* captures the dynamics for a specific community one needs to consider and account for many different moving parts (*e.g.,*). So when developing a model it makes sense that you prioritise the aspect of the prediction/construction task that has the most value for your research goal, acknowledging that a model might fall short in others. The thing is that with the growing suite of approaches to generating networks it is important that we don't lose sight of the core philosophy behind the model we use and to ensure that we are using the model best suited to what we want to be accomplishing.

* It is perhaps useful to start with asking why do we want/need models to generate networks. This can be broadly thought of to fall into two categories. Build networks because we want to build concepts vs build networks because we want specificity. Broadly this means that we either want to construct/predict a collection of interactions (generate networks) or a network of interactions (predict interactions).

Arguably the need for methods and tools for constructing interaction networks arises from two different (but still aligned) places of interest within the field of network ecology. On the one side sits the researcher who is interested in generating a set of ecologically plausible but not necessarily realised 'in the field' networks for the purpose of running further simulations (*e.g.,* extinction sim **TODO**) or understanding some higher-level process/concept (*e.g.,* energetics **TODO**). This researcher is contrasted by one that is interested in constructing real-world, location specific, interaction data in lieu of inventorying interactions based n observations made in the field [@strydomRoadmapPredictingSpecies2021]. Of course these two categories are not two distinct, mutually exclusive, groups but can rather be viewed as operating on a gradient ranging from a need for generality (*i.e.,* creating a network that, when taken in aggregate, the distribution of links (interactions) between species are ecologically plausible) to a need for specificity (local-level predictions between specific species).

* Brief history of the development of tools within the context of the two different fields? Sort of where the theory/body of work was based and how that has changed?

  * Core mechanistic differences that models will work at --- some are really concerned about (and thus constrained by) structure, others are more mechanistic in nature *i.e.,* species *a* has the capacity to eat species *b* because traits

  * In certain situations structure is 'enough' but there may be use cases where we are really interested in the node-level interactions *i.e.,* species identity is a thing we care about and need to be able to retrieve specific interactions at specific nodes correctly. 
  
  * What is the purpose of generating a network? Is it an element of a bigger question we are asking, *e.g.,* I want to generate a series of networks to do some extinction simulations/bioenergetic stuff OR are we looking for a 'final product' network that is relevant to a specific location? (this can still be broad in geographic scope).

* A breakdown of wanting to generate a network; statement of need and core philosophies

* A breakdown of wanting to predict an interaction; statement of need [@jordanoSamplingNetworksEcological2016; @jordanoChasingEcologicalInteractions2016; @poisotGlobalKnowledgeGaps2021] and core philosophies (trait-matching, coexistence)

* Stands to reason then that we have developed methods that specialise in one or the other. Which comes at a cost of 'performance' in other aspects. Knowing how the different model families stack up to each other is thus valuable and that is kinda what we are trying to achieve.

@cohenStochasticTheoryCommunity1985 states that *"\[Their\] approach is more like gross anatomy than like physiology... that is, the gross anatomy is frozen, rather than in motion."*.

Interestingly @williamsSuccessItsLimits2008 also explicitly talk about *structural* food-web models in their introduction... so how I see it that means that there has always been this inherent acknowledgement that models are functioning at a specific 'network level'.

### Model families

Given the large number of models that have been developed it is perhaps more meaningful to group models into families with the idea that models from the same family will yield similar results because they play by similar rules. These rules referring to the underlying philosophy as to what structures either networks or the interactions within them (see @fig-concept panel A).

![Conceptual figure of the 'network prediction'. Panel A shows where the model families fall in the the context of being models that predict networks or models that predict interactions space. Panel B serves to highlight the characteristics one might like to 'test'/benchmark for a model based on it being either a network or interaction predicting model](images/concept.jpeg){#fig-concept}

**Null models:** The interactions between species occurs regardless of the identity of the species (*i.e.,* species have no agency) and links are randomly distributed throughout the network. There is however the assumption that a network will be constrained by the number of links. Type I [@fortunaHabitatLossStructure2006], where interactions happen proportionally to connectance and Type II [@bascompteNestedAssemblyPlantanimal2003], where interactions happen proportionally to the joint degree of the two species involved. These two models are equivalent to the Erdos-Renyi and Configuration models [@newmanNetworksIntroduction2010] (check that though).

**Neutral models:** Based on the theory that interactions occur as the result of the abundance of species (*i.e.,* the species still has no agency but its abundance does?). See @pomeranzInferringPredatorPrey2019

**Resource models:** In the context of network generating models this is perhaps the most well known family of models. Essentially these models can be viewed as being based on the idea of resource partitioning and that the number of links scale with species richness (maybe not directly that but these models are link constrained). That is there is some sort of hierarchical feeding based on how a 'resource' is partitioned. This includes the cascade model [@cohenCommunityFoodWebs1990], which much like the name suggests the cascade model rests on the idea that species feed on one another in a hierarchical manner. This rests on the assumption that the links within a network are variably distributed across the network; with the proportion of links decreasing as one moves up the trophic levels (*i.e.,* 'many' prey and 'few' predators). The niche model [@williamsSimpleRulesYield2000] introduces the idea that species interactions are based on the 'feeding niche' of a species. Broadly, all species are randomly assigned a 'feeding niche' and all species that fall in this niche can be consumed by that species. Finally, the nested hierarchy model[@cattinPhylogeneticConstraintsAdaptation2004] **TODO**.

**Energetic models:** Broadly this family of models is rooted in feeding theory and allocates the links between species based on energetics. This means that the model is focused on predicting not only the number of links in a network but also the arrangement of these links based on the diet breadth of a species. The diet breadth model [@beckermanForagingBiologyPredicts2006] as well as its allometrically scaled cousin the allometric diet breadth model (ADBM) [@petcheySizeForagingFood2008] determine links between species based on the energetic content, handling time, and density of species.

> @gravelInferringFoodWeb2013 also poses an interesting cross-over between the adbm and niche model.

**Binary classifiers:** 

**Graph embedding:** This family of approaches has been extensively discussed in @strydomGraphEmbeddingTransfer2023 but can be broadly explained as an approach that estimates latent features from observed networks that can be used to predict interactions. @strydomFoodWebReconstruction2022 presents a specific use case that is based on transfer learning and the idea that interactions are evolutionarily conserved and that we can use known networks, and this evolutionary relationship to predict interactions for a given species pool. **TODO** Log-ratio [@rohrModelingFoodWebs2010]

**Trait hierarchy:** Here I envision models that present an *a priori* trait hierarchy that determines feeding links between species. That is, there is an element of 'expert knowledge' that also comes into play... Something like PFIM [@shawFrameworkReconstructingAncient2024] is what I imagine fitting in here...

**GLM** [@caronAddressingEltonianShortfall2022]: To confirm

**Expert knowledge:** (boots on the ground ecology)

### Model benchmarking

* 'Testing' the performance of a model is going to depend on some of the core limitations of the model itself thus it makes sense to think of two sets benchmarking rules for network and interaction prediction models respectively (see @fig-concept panel B).

* When it comes to network models we are concerned with the 'preservation' of structure and distribution of links across the network. For interaction models we want to ensure that we are able to retrieve interactions that really exist but also those that cannot exist (*sensu* forbidden links @jordanoSamplingNetworksEcological2016)

#### Benchmarking network models

* Maybe look at some of the historic papers that compare some of the 'resource models'

#### Benchmarking interaction models

* See @poisotGuidelinesPredictionSpecies2023

* Need to discuss the key differences and implications between predicting a metaweb (*sensu* @dunneNetworkStructureFood2006) and a network realisation. Maybe also  @poisotSpeciesWhyEcological2015 that discuss how the local factors are going to play a role.

## Data & Methods {#sec-data-methods}

### Selecting models

This section depends on if we go the family route and where we introduce them. But a more extended description of each model can be found in the `Extended Model Description` notebook (I'm trying to work out how to embed this...)

I know tables are awful but in this case they may make more sense. Also I don't think I'm at the point where I can say that the table is complete/comprehensive but it getting there Not sure about putting in some papers that have used the model - totes happy to drop those I think...

| Model               | Core Mechanism | Predicts     | Specificity      | Interaction   | Data-driven |
|------------|------------|------------|------------|------------|------------|
| random              | random         | networks     | species agnostic | binary        | no          |
| cascade             | structural     | networks     | species agnostic | binary        | no          |
| niche               | structural     | networks     | species agnostic | binary        | no          |
| nested hierarchical | structural     | networks     | species agnostic | binary        | no          |
| ADBM                | mechanistic    | interactions | energetics       | quantitative  |             |
| log-ratio           |                | interactions |                  |               |             |
| PFIM                | mechanistic    | interactions | trait based      |               |             |
| graph embedding     | embedding      | interactions | evolutionary     | probabilistic | yes         |
| trait model         | mechanistic    | interactions | trait based      |               | yes         |
| matching            |                |              |                  |               |             |

: Lets make a table that gives an overview of the different topology generators that we will look at. Here I take 'data-driven' to refer to the need for 'real world' data. This can probably be approached in a different way though maybe? {#tbl-history}

### Datasets used

* For network models makes sense to drop datasets from Mangal

* 'Elite' number of datasets for interaction models

> Here I think we need to span a variety of domains, at minimum aquatic and terrestrial but maybe there should be a 'scale' element as well *i.e.,* a regional and local network. I think there is going to be a 'turning point' where structural will take over from mechanistic in terms of performance. More specifically at local scales bioenergetic constraints (and co-occurrence) may play a bigger role in structuring a network whereas at the metaweb level then mechanistic may make more (since by default its about who can potentially interact and obviously not constrained by real-world scenarios) *sensu* @caronTrophicInteractionModels2023. Although having said that I feel that contradicts the idea of backbones (*sensu* Bramon Mora (sp?) et al & Stouffer et al) But that might be where we get the idea of core *structure* vs something like linkage density. So core things like trophic level/chain length will be conserved but connectance might not (I think I understand what I'm trying to say here)

I think we should also use the Dunne [@dunneCompilationNetworkAnalyses2008]. Because 1) it gives the paleo-centric methods their moment in the sun and 2) I think it also brings up the interesting question of can we use modern structure to predict past ones?

### Model comparison

For now the (still essentially pending) workflow/associated code can be found at the following repository [BecksLab/topology_generators](https://github.com/BecksLab/topology_generators). This will reflect that which is shown in panel *B* of @fig-concept.

* Data 'cost' (some methods might need a lot lot of supporting data vs something very light weight)
* I think it would be remiss to not also take into consideration computational cost
* Something about the network output - I'm acknowledging my biases and saying that probabilistic (or *maybe* weighted) links are the way

#### Network models

Want to compare real vs predicted and then get something that looks like @fig-topology

* *Shape:* do the models construct tall 'pencil' vs flat 'pancake' networks (Beckerman 2024, pers comms), generality/vulnerability, chain length (?)
* *Structure:* Predicting 'structure' - SVD [@strydomSVDEntropyReveals2021] but maybe something like nestedness as well (?)
* *Links:* are the number of links preserved (most network predicting are to some extend link constrained but useful to see)

#### Interaction models

* Look at what @poisotGuidelinesPredictionSpecies2023 has to say
* \% links correctly retrieved
* TSS/ROC-AUC
* Maybe same measures we use for the network models

#### PVA (action plan)

1.  Shortlist/finalise the different topo generators
2.  collate/translate into `Julia`
    -   *e.g.,* some models wil be in SpeciesInteractionNetworks.jl (new EcoNet); I know (parts of) the transfer learning stuff is and the niche model
    -   others will need to be coded out (the more simpler models should be easier)
3.  Curate networks for the different datasets/scenarios we select - I feel like there might be some scenarios that we can't do all models for all datasets but maybe I'm being a pessimist.
    -   Need to also think about where one might find the additional data for some of the models...
        -   Body size: @herbersteinAnimalTraitsCuratedAnimal2022 - Although maybe Andrew has strong thotsTM RE the one true body size database to rule them all...
        -   Other trait sources: @wilmanEltonTraitsSpecieslevelForaging2014 and @jonesPanTHERIASpecieslevelDatabase2009
        -   This is where we'll get the paleo traits from if I'm correct @bambachAutecologyFillingEcospace2007
        -   Phylogeny stuff: @uphamInferringMammalTree2019 (what we used for TL but its only mammals...) but I'm sure there will be others
    -   Also limitation of scope... *e.g.,* do we even dare to think about including plants/basal producers (see *e.g.,* @valdovinosBioenergeticFrameworkAboveground2023)
    -   Taxonomic harmonisation - something to think about and check

## Results

@cohenStochasticTheoryCommunity1985 actually tells us that the cascade model only really works for communities that range from 3-33 species... and @williamsSuccessItsLimits2008 also highlights how structural models really only work for small communities

### Quantitative stuff

{{< embed notebooks/model_quantitative.qmd#fig-topology >}}

This might actually be an awful way to try and summarise the data but rolling with it for now...

## Discussion

I think a big take home will (hopefully) be how different approaches do better in different situations and so you as an end user need to take this into consideration and pick accordingly. I think @petcheyFitEfficiencyBiology2011 might have (and share) some thoughts on this (thanks Andrew). I feel like I need to look at @berlowGoldilocksFactorFood2008 but maybe not exactly in this context but vaguely adjacent.

An interesting thing to also think about (and arguably it will be addressed based on some of the other thoughts and ideas) is data dependant and data independent 'parametrisation' of the models...

I probably think about this point too much but a point of discussion that I think will be interesting to bring up the idea that if a model is missing a specific pairwise link but doing well at the structural level then when does it matter? I think this is covered with the whole node vs graph level performance but I kind of just want to bring it up here again because also one of those things that I think about a bit too much probably...

Thinking very long term here and maybe a bit beyond the scope but also thinking about a multi- model approach? So in other words using one model to build an initial network but maybe a second one to constrain it a bit better. I blame this thought on the over-connected PFIM food webs...

Linking to previous point but framing this as a call to action that we have models that predict networks very well and models that predict interactions very well but nothing that is doing well at predicting both - this is where we should be focusing our attention when it comes to furthering model development.

## References {.unnumbered}

::: {#refs}
:::