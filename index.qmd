---
title: T is for Topology
author:
  - name: Tanya Strydom
    id: ts
    orcid: 0000-0001-6067-1349
    corresponding: true
    email: t.strydom@sheffield.ac.uk
    roles:
      - Nonsense
      - Rascality
      - Visualisation (although absent)
    affiliation:
      - id: sheffield
        name: School of Biosciences, University of Sheffield
  - name: Timothée Poisot
    id: tp
    orcid: 0000-0002-0735-5184
    corresponding: false
    roles: []
    affiliations:
      - Université de Montreal
      - Québec Centre for Biodiversity Sciences
  - name: Andrew P. Beckerman
    id: apb
    orcid: 0000-0002-7859-8394
    corresponding: false
    roles: []
    affiliations:
      - ref: sheffield
funding: "The author(s) received no specific funding for this work. Well they did I just haven't done the homework"
keywords:
  - food web
  - network construction
abstract: |
  There are many reasons one might want to generate a network and there are many tools on the market that might make that possible. However not all tools are created equally and there is reason to assume that not all networks will suit most purposes. Here the aim is to compare and contrast the different topology generating tools that are on the market and see where they shine and where they fall flat. There probably isn't one model to rule them all but it doesn't mean that we shouldn't be critical when we think about the model we want to use.
plain-language-summary: |
  We want to know a bit more about the different network topology generators (prediction tools) and how they differ - *i.e.,*  their strengths and weaknesses
date: last-modified
bibliography: references.bib
citation:
  container-title: Some fancy journal
number-sections: true
jupyter: python3
---

## Introduction

-   In order to construct a 'perfect' network *i.e.,* one which *perfectly* captures the dynamics for a specific community one needs to consider and account for many different moving parts (*e.g.,*). So when developing a model it makes sense that you prioritise the aspect of the prediction/construction task that has the most value for your research goal, acknowledging that a model might fall short in others. The thing is that with the growing suite of approaches to generating networks it is important that we don't lose sight of the core philosophy behind the model we use and to ensure that we are using the model best suited to what we want to be accomplishing.

-   It is perhaps useful to start with asking why do we want/need models to generate networks. This can be broadly thought of to fall into two categories. Build networks because we want to build concepts vs build networks because we want specificity. Broadly this means that we either want to construct/predict a collection of interactions (generate networks) or a network of interactions (predict interactions).

Arguably the need for methods and tools for constructing interaction networks arises from two different (but still aligned) places of interest within the field of network ecology. On the one side sits the researcher who is interested in generating a set of ecologically plausible networks for the purpose of running further simulations (*e.g.,* extinction simulations) or understanding some higher-level process/concept (*e.g.,* understanding energy flows), importantly these networks do not require any level of species specificity and it is more the arrangements of the nodes (species) within the context of network structure that is of value. This researcher is contrasted by one that is interested in constructing real-world, location specific, interaction data for a specific collection of species (community). This is driven by the need for researchers to find alternative ways to infer the interactions between species as a way to overcome the inherit challenges of inventorying interaction in the field [@morales-castillaInferringBioticInteractions2015; @strydomRoadmapPredictingSpecies2021]. Of course these two categories are not distinct, mutually exclusive, groups but can rather be viewed as operating on a gradient ranging from a need for generality (*i.e.,* creating a network that, when taken in aggregate, the distribution of links (interactions) between species are ecologically plausible) to a need for specificity (local-level predictions between specific species).

-   Brief history of the development of tools within the context of the two different fields? Sort of where the theory/body of work was based and how that has changed?

    -   Core mechanistic differences that models will work at --- some are really concerned about (and thus constrained by) structure, others are more mechanistic in nature *i.e.,* species *a* has the capacity to eat species *b* because traits

    -   In certain situations structure is 'enough' but there may be use cases where we are really interested in the node-level interactions *i.e.,* species identity is a thing we care about and need to be able to retrieve specific interactions at specific nodes correctly.

    -   What is the purpose of generating a network? Is it an element of a bigger question we are asking, *e.g.,* I want to generate a series of networks to do some extinction simulations/bioenergetic stuff OR are we looking for a 'final product' network that is relevant to a specific location? (this can still be broad in geographic scope).

-   A breakdown of wanting to generate a network; statement of need and core philosophies

-   A breakdown of wanting to predict an interaction; statement of need [@jordanoSamplingNetworksEcological2016; @jordanoChasingEcologicalInteractions2016; @poisotGlobalKnowledgeGaps2021] and core philosophies (trait-matching, coexistence, evolutionary backbones)

-   Stands to reason then that we have developed methods that specialise in one or the other. Which comes at a cost of 'performance' in other aspects. Knowing how the different model families stack up to each other is thus valuable.

@cohenStochasticTheoryCommunity1985 states that *"\[Their\] approach is more like gross anatomy than like physiology... that is, the gross anatomy is frozen, rather than in motion."*.

Interestingly @williamsSuccessItsLimits2008 also explicitly talk about *structural* food-web models in their introduction... so how I see it that means that there has always been this inherent acknowledgement that models are functioning at a specific 'network level'.

## Model families

Given the large number of models that have been developed it is perhaps more meaningful to group models into families with the idea that models from the same family will yield similar results because they play by similar rules. These rules referring to the underlying philosophy as to what structures either networks or the interactions within them (see @fig-concept panel A).

![Conceptual figure of the 'network prediction'. Panel A shows where the model families fall in the the context of being models that predict networks or models that predict interactions space. Panel B serves to highlight the characteristics one might like to 'test'/benchmark for a model based on it being either a network or interaction predicting model](images/concept.jpeg){#fig-concept}

**Null models:** The interactions between species occurs regardless of the identity of the species (*i.e.,* species have no agency) and links are randomly distributed throughout the network. There is however the assumption that a network will be constrained by the number of links. Type I [@fortunaHabitatLossStructure2006], where interactions happen proportionally to connectance and Type II [@bascompteNestedAssemblyPlantanimal2003], where interactions happen proportionally to the joint degree of the two species involved. These two models are equivalent to the Erdos-Renyi [@erdosRandomGraphs1959] and Configuration models [@newmanNetworksIntroduction2010] respectively (check that though).

**Neutral models:** Based on the theory that interactions occur as the result of the abundance of species (*i.e.,* the species still has no agency but its abundance does?). See @pomeranzInferringPredatorPrey2019

**Resource models:** Based on the idea that networks follow a trophic hierarchy and that species interactions can be determined using a single dimension (the “niche axis”) [@allesinaGeneralModelFood2008]. Essentially these models can be viewed as being based on the idea of resource partitioning (niches) along a one-dimensional resource and that the number of links scale with species richness (linear link scaling). That is there is some sort of hierarchical feeding based on how a 'resource' is partitioned. This includes the cascade model [@cohenCommunityFoodWebs1990], which much like the name suggests the cascade model rests on the idea that species feed on one another in a hierarchical manner. This rests on the assumption that the links within a network are variably distributed across the network; with the proportion of links decreasing as one moves up the trophic levels (*i.e.,* 'many' prey and 'few' predators). The niche model [@williamsSimpleRulesYield2000] introduces the idea that species interactions are based on the 'feeding niche' of a species. See also probabilistic niche model [@williamsProbabilisticNicheModel2010] Broadly, all species are randomly assigned a 'feeding niche' and all species that fall in this niche can be consumed by that species. Finally, the nested hierarchy model [@cattinPhylogeneticConstraintsAdaptation2004], which adds some component of phylogenetic clustering/signal... so not a single dimension? **TODO**.

**Generative models:** (this is maybe a bit of a bold term to use). MaxEnt [@banvilleWhatConstrainsFood2023], (maybe) stochastic block [@xieCompletenessCommunityStructure2017].

**Feeding models:** Broadly this family of models is rooted in feeding theory and allocates the links between species based on energetics. This means that the model is focused on predicting not only the number of links in a network but also the arrangement of these links based on the diet breadth of a species. The diet breadth model [@beckermanForagingBiologyPredicts2006] as well as its allometrically scaled cousin the allometric diet breadth model (ADBM) [@petcheySizeForagingFood2008] determine links between species based on the energetic content, handling time, and density of species. See also @deangelisModelTropicInteraction1975

> @gravelInferringFoodWeb2013 also poses an interesting cross-over between the adbm and niche model.

**Binary classifiers:** The task of predicting if an interaction will occur between a species pair is treated as a statistical binary classification task. Here the task is to correlate 'real world' interaction data with a suitable ecological proxy for which data is more widely available (*e.g.,* traits). Model families often used include generalised linear models [*e.g.,* @caronAddressingEltonianShortfall2022 use a tait-based approach], random forest [*e.g.,* @llewelynPredictingPredatorPrey2023], trait-based k-NN [*e.g.,* @desjardins-proulxEcologicalInteractionsNetflix2017], and Bayesian models[*e.g.,* @eklofSecondaryExtinctionsFood2013; @cirtwillQuantitativeFrameworkInvestigating2019]

**Graph embedding:** This family of approaches has been extensively discussed in @strydomGraphEmbeddingTransfer2023 but can be broadly explained as an approach that estimates latent features from observed networks that can be used to predict interactions. @strydomFoodWebReconstruction2022 uses a transfer learning framework (specifically using a random dot product graph for embedding) based around the idea that interactions are evolutionarily conserved and that we can use known networks, and phylogenetic relationships, to predict interactions for a given species pool. **TODO** Log-ratio [@rohrModelingFoodWebs2010]

**Trait matching:** Here I envision models that present an *a priori* set of rules that determines feeding links between species; specifically based on species traits. That is, there is an element of 'expert knowledge' that also comes into play... Something like PFIM [@shawFrameworkReconstructingAncient2024] is what I imagine fitting in here...

**Expert knowledge:** Not so much about empirical observations but more the idea of using human power/knowledge to create an assemblage of interactions for a specific community. This can include empirical data but can also make use of knowledge about ecological features (such as traits or co-occurrence) and how those can function as proxies for interactions [*e.g.,* @morales-castillaInferringBioticInteractions2015]. Or alternatively the value of 'local' knowledge and having specific individuals sitting around a table and assigning a value of how confident they are that a specific species pair are likely to interact [*e.g.,* @dunneCompilationNetworkAnalyses2008], or a combination of published and grey literature [*e.g.,* @maioranoTETRAEUSpecieslevelTrophic2020].

## Model benchmarking

-   'Testing' the performance of a model is going to depend on some of the core limitations of the model itself thus it makes sense to think of two sets benchmarking rules for network and interaction prediction models respectively (see @fig-concept panel B).

-   When it comes to network models we are concerned with the 'preservation' of structure and distribution of links across the network. For interaction models we want to ensure that we are able to retrieve interactions that really exist but also those that cannot exist (*sensu* forbidden links @jordanoSamplingNetworksEcological2016)

> "As long as these predictions are not perfect, some interactions will be predicted at the ‘wrong’ position in the network; these measures cannot describe the structural effect of these mistakes. On the other hand, measures of network structure can have the same value with interactions that fall at drastically different positions; this is in part because a lot of these measures covary with connectance, and in part because as long as these values are not 0 or their respective maximum, there is a large number of network configurations that can have the same value." - @poisotGuidelinesPredictionSpecies2023

### Benchmarking network models

-   Maybe look at some of the historic papers that compare some of the 'resource models'

-   See also @allesinaGeneralModelFood2008 and the likelihood function that they use for model selection

- Look at @vermaatMajorDimensionsFoodweb2009

> "Possibly, the most striking caveat of the use of summary statistics is that it cannot tell us whether or not a model is able to fully replicate empirical networks." - @allesinaGeneralModelFood2008

### Benchmarking interaction models

-   Main concern with predicting interactions is that we want to test the 'quality' of the links we are predicting (both true positives and true negatives), but the inherit sparsity (meaning high class imbalance) means that we also need to look at the balance of these predictions.

-   "Both precision and recall may be useful in cases where there is imbalanced data. However, it may be valuable to prioritize one over the other in cases where the outcome of a false positive or false negative is costly."

-   Caveat regarding the use of real world interaction data both for training and validating predictions? *e.g.,* Poisot, Ouellet, et al. et al 2021 and Catchen et al 2023

-   See @poisotGuidelinesPredictionSpecies2023

    -   skill (ability to make the right prediction; evaluate whether low prevalence can lull us into a false sense of predictive accuracy)

    -   bias (trends towards systematically over-predicting one class)

    -   class imbalance (the relative number of cases representing interactions)

-   "These results suggest that learning from a dataset with very low connectance can be a different task than for more connected networks: it becomes increasingly important to capture the mechanisms that make an interaction exist, and therefore having a slightly more biased training dataset might be beneficial. As connectance increases, the need for biased training sets is less prominent, as learning the rules for which interactions do not exist starts gaining importance"

-   Need to discuss the key differences and implications between predicting a metaweb (*sensu* @dunneNetworkStructureFood2006) and a network realisation. Maybe also @poisotSpeciesWhyEcological2015 that discuss how the local factors are going to play a role.

## Data & Methods {#sec-data-methods}

### Selecting models

This section depends on if we go the family route and where we introduce them. But a more extended description of each model can be found in the `Extended Model Description` notebook (I'm trying to work out how to embed this...)

I know tables are awful but in this case they may make more sense. Also I don't think I'm at the point where I can say that the table is complete/comprehensive but it getting there Not sure about putting in some papers that have used the model - totes happy to drop those I think...

| Model family       | Theory                                                                                                               | Predicts     | Outcome (these terms could be better...) | Constraints | Interaction   | 'Real world' data               |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| null               | Network structure is random                                                                                          | network      | random                                   | link        | binary        | no                              |
| neutral            | Network structure is random, but species abundance plays a role                                                      | network      |                                          |             |               | abundance                       |
| interval           | Networks are interval, can be ordered on a 'niche axis'                                                              | network      | 'random'                                 | link        | binary        | no                              |
| generative         | Interactions are determined by structural features of the network (*pending*)                                        | network      | 'random'                                 |             |               |                                 |
| energetic          | Interactions are determined by foraging theory (feeding links)                                                       |              | deterministic                            |             | binary        | yes (body size, ...)            |
| graph embedding    | Interactions can be predicted from the latent traits of networks                                                     | interactions | deterministic                            |             | probabilistic | yes (network, ecological proxy) |
| trait matching     | Interactions can be inferred by a mechanistic framework/relationships                                                | interactions | deterministic                            |             |               | yes (expert knowledge, trait)   |
| binary classifiers | Interactions can be predicted by learning the relationship between interactions and ecologically relevant predictors | interactions | deterministic                            |             | probabilistic | yes (interaction, trait)        |
| expert knowledge   | 'Boots on the ground' ecological knowledge and observations                                                          | interactions |                                          |             |               |                                 |

: Lets make a table that gives an overview of the different model families that we will look at. Here I take 'data-driven' to refer to the need for 'real world' data. This can probably be approached in a different way though maybe? {#tbl-history}

### Datasets used

-   For network models makes sense to drop datasets from Mangal

-   'Elite' number of datasets for interaction models

> Here I think we need to span a variety of domains, at minimum aquatic and terrestrial but maybe there should be a 'scale' element as well *i.e.,* a regional and local network. I think there is going to be a 'turning point' where structural will take over from mechanistic in terms of performance. More specifically at local scales bioenergetic constraints (and co-occurrence) may play a bigger role in structuring a network whereas at the metaweb level then mechanistic may make more (since by default its about who can potentially interact and obviously not constrained by real-world scenarios) *sensu* @caronTraitmatchingModelsPredict2024. Although having said that I feel that contradicts the idea of backbones (*sensu* Bramon Mora (sp?) et al & Stouffer et al) But that might be where we get the idea of core *structure* vs something like linkage density. So core things like trophic level/chain length will be conserved but connectance might not (I think I understand what I'm trying to say here)

I think we should also use the @dunneCompilationNetworkAnalyses2008 work. Because 1) it gives the paleo-centric methods their moment in the sun and 2) I think it also brings up the interesting question of can we use modern structure to predict past ones?

### Model comparison

For now the (still essentially pending) workflow/associated code can be found at the following repository [BecksLab/topology_generators](https://github.com/BecksLab/topology_generators). This will reflect that which is shown in panel *B* of @fig-concept.

-   Data 'cost' (some methods might need a lot lot of supporting data vs something very light weight)
-   I think it would be remiss to not also take into consideration computational cost
-   Something about the network output - I'm acknowledging my biases and saying that probabilistic (or *maybe* weighted) links are the way

#### Network models

Want to compare real vs predicted and then get something that looks like @fig-topology

-   connectance, nestedness (Bastolla et al., 2009), modularity (Barber, 2007), asymmetry (Delmas et al., 2018), and Jaccard network dissimilarity (Canard et al., 2014)

-   *Shape:* do the models construct tall 'pencil' vs flat 'pancake' networks (Beckerman 2024, pers comms), generality/vulnerability, chain length (?)

-   *Structure:* Predicting 'structure' - SVD [@strydomSVDEntropyReveals2021] but maybe something like nestedness as well (?)

-   *Links:* are the number of links preserved (most network predicting models are to some extend link constrained but useful to see)

#### Interaction models

-   Based on @poisotGuidelinesPredictionSpecies2023:
    -   Precision-Recall (PR-AUC) - performance
    -   Matthews correlation coefficient (MCC) - accuracy
-   Maybe same measures we use for the network models

#### PVA (action plan)

1.  Shortlist/finalise the different topo generators
2.  collate/translate into `Julia`
    -   *e.g.,* some models wil be in SpeciesInteractionNetworks.jl (new EcoNet); I know (parts of) the transfer learning stuff is and the niche model
    -   others will need to be coded out (the more simpler models should be easier)
3.  Curate networks for the different datasets/scenarios we select - I feel like there might be some scenarios that we can't do all models for all datasets but maybe I'm being a pessimist.
    -   Need to also think about where one might find the additional data for some of the models...
        -   Body size: @herbersteinAnimalTraitsCuratedAnimal2022 - Although maybe Andrew has strong thotsTM RE the one true body size database to rule them all...
        -   Other trait sources: @wilmanEltonTraitsSpecieslevelForaging2014 and @jonesPanTHERIASpecieslevelDatabase2009
        -   This is where we'll get the paleo traits from if I'm correct @bambachAutecologyFillingEcospace2007
        -   Phylogeny stuff: @uphamInferringMammalTree2019 (what we used for TL but its only mammals...) but I'm sure there will be others
    -   Also limitation of scope... *e.g.,* do we even dare to think about including plants/basal producers (see *e.g.,* @valdovinosBioenergeticFrameworkAboveground2023)
    -   Taxonomic harmonisation - something to think about and check

## Results

@cohenStochasticTheoryCommunity1985 actually tells us that the cascade model only really works for communities that range from 3-33 species... and @williamsSuccessItsLimits2008 also highlights how structural models really only work for small communities

### Qualitative stuff

Maybe not the best term to use but thinking here about practical limitations of the different families. This can include thinking about:

-   scale limitations (time or space); *e.g.,* a metaweb is going to encapsulate but not distinguish between different seasons or locations
-   data needed. I think this can be in the form of real world datasets (*e.g.,* traits) but also *a priori* knowledge (*e.g.,* having to define the constraints of a niche model)
-   computational costs

![I still haven't given up on a sort of venn diagram idea but maybe it going to be more of a venn-flow chart hybrid...](images/model_venn.png)

### Quantitative stuff

{{< embed notebooks/model_quantitative.qmd#fig-topology >}}

This might actually be an awful way to try and summarise the data but rolling with it for now...

## Discussion

-   I think a big take home will (hopefully) be how different approaches do better in different situations and so you as an end user need to take this into consideration and pick accordingly. I think @petcheyFitEfficiencyBiology2011 might have (and share) some thoughts on this (thanks Andrew). I feel like I need to look at @berlowGoldilocksFactorFood2008 but maybe not exactly in this context but vaguely adjacent.

-   An interesting thing to also think about (and arguably it will be addressed based on some of the other thoughts and ideas) is data dependant and data independent 'parametrisation' of the models...

-   Why do interaction models do so badly at predicting structure? Nuance of metaweb vs realisation but also time? At the core of it interaction models are trained on existing interaction data; this is data that are most likely closer to a metaweb than a local realisation even if they are being inventoried at a small scale.

> *"we highlight an interesting paradox: the models with the best performance measures are not necessarily the models with the closest reconstructed network structure."* - @poisotGuidelinesPredictionSpecies2023

-   *Do we need network models to predict interactions and interaction models to predict structure?* (lets not think about that too hard or I might just have to sit in silence for a while...)

-   It will be interesting to bring up the idea that if a model is missing a specific pairwise link but doing well at the structural level then when does it matter?

-   Close out with a call to action that we have models that predict networks very well and models that predict interactions very well but nothing that is doing well at predicting both - this is where we should be focusing our attention when it comes to furthering model development. (we need models that will fill the space in the top right quadrant of panel A in @fig-concept)

## References {.unnumbered}

::: {#refs}
:::